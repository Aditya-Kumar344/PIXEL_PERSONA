{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings( \"ignore\" )\n",
        "\n",
        "class LR():\n",
        "\tdef __init__(self, act,lR=0.01, n_iters=1000):\n",
        "\t\tself.lR = lR\n",
        "\t\tself.n_iters = n_iters\n",
        "\t\tself.act = act if act != None else 'sigmoid'\n",
        "\n",
        "\tdef activator(self,x):\n",
        "\t\tif self.act=='relu':\n",
        "\t\t\tres = [i  if i>0 else 0 for i in x]\n",
        "\t\t\tres = np.array(res)\n",
        "\t\t\treturn res\n",
        "\t\telif self.act=='prelu':\n",
        "\t\t\tres = [i*self.lR  if i>0 else 0 for i in x]\n",
        "\t\t\tres = np.array(res)\n",
        "\t\t\treturn res\n",
        "\t\telif self.act=='softmax':\n",
        "\t\t\texp_x=np.exp(x-np.max(x))\n",
        "\t\t\treturn exp_x/np.sum(exp_x)\n",
        "\t\telse: return 1/(1+np.exp(-x))\n",
        "\n",
        "\n",
        "\tdef fit(self, X, y):\n",
        "\t\tX = np.array(X)\n",
        "\t\tn_samples, n_features = X.shape\n",
        "\t\tself.weights = np.zeros(n_features)\n",
        "\t\tprint(self.weights.shape, X.shape, sep=' ')\n",
        "\t\tself.bias = 0\n",
        "\t\tfor i in range(self.n_iters):\n",
        "\t\t\tlinear_pred = np.dot(X, self.weights) + self.bias\n",
        "\t\t\tpredictions = self.activator(linear_pred)\n",
        "\n",
        "\t\t\tdw = (2/n_samples) * np.dot(X.T, (predictions-y))\n",
        "\t\t\tdb = (2/n_samples) * np.sum(predictions-y)\n",
        "\n",
        "\t\tself.weights = self.weights - self.lR*dw\n",
        "\t\tself.bias = self.bias - self.lR*db\n",
        "\n",
        "\tdef predict(self, X):\n",
        "\t\tlinear_pred = np.dot(X, self.weights)+ self.bias\n",
        "\t\ty_pred = self.activator(linear_pred)\n",
        "\t\tclass_pred = [0 if y<=0.5 else 1 for y in y_pred]\n",
        "\t\treturn class_pred\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/loan_data.csv')\n",
        "df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "print(df['loan_status'].unique())\n",
        "\n",
        "df.drop('person_age', axis=1, inplace=True)\n",
        "\n",
        "print(df.shape)\n",
        "print(df.columns)\n",
        "\n",
        "X = df[[ 'person_income', 'person_emp_exp', 'loan_amnt', 'loan_int_rate',\n",
        "       'loan_percent_income', 'cb_person_cred_hist_length', 'credit_score']]\n",
        "Y = df['loan_status']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=12345678)\n",
        "\n",
        "model = LR('softmax', lR=0.01, n_iters=1000)\n",
        "model.fit(X_train, Y_train)\n",
        "model1 = LogisticRegression()\n",
        "model1.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "Y_pred1 = model1.predict(X_test)\n",
        "\n",
        "def accuracy(y_pred, y_test):\n",
        "    return np.sum(y_pred==y_test)/len(y_test)\n",
        "\n",
        "acc = accuracy(Y_pred, Y_test)\n",
        "print(\"Our accuracy \", acc)\n",
        "acc1 = accuracy(Y_pred1, Y_test)\n",
        "print(\"Sklearn accuracy \",acc1)\n"
      ],
      "metadata": {
        "id": "4lvUBbnfFXg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fff500-f56a-4cfd-8378-88186b4a564e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(45000, 9)\n",
            "Index(['person_age', 'person_income', 'person_emp_exp', 'loan_amnt',\n",
            "       'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n",
            "       'credit_score', 'loan_status'],\n",
            "      dtype='object')\n",
            "[1 0]\n",
            "(45000, 8)\n",
            "Index(['person_income', 'person_emp_exp', 'loan_amnt', 'loan_int_rate',\n",
            "       'loan_percent_income', 'cb_person_cred_hist_length', 'credit_score',\n",
            "       'loan_status'],\n",
            "      dtype='object')\n",
            "(7,) (31500, 7)\n",
            "Our accuracy  0.7797037037037037\n",
            "Sklearn accuracy  0.8196296296296296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are 14 different columns, with the last column, loan_status being the target variable. The other columns contain various factors that may help determining in whether loan will be allocated or not. Out of aforesaid columns, age and gender may be dropped as they might perhaps not be a clear indicator. Also, we will be dropping all the text columns, as during logistic regression we cannot use non numerical values"
      ],
      "metadata": {
        "id": "I88Ijq3JF_Ry"
      }
    }
  ]
}
